{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, LeaveOneOut\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.metrics import r2_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import log_loss, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.exceptions import DataConversionWarning\n",
    "# warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "train_values = np.loadtxt(\"train_values.csv\", delimiter=\",\", dtype=object)\n",
    "train_labels = np.loadtxt(\"train_labels.csv\", delimiter=\",\", dtype=object)\n",
    "\n",
    "\n",
    "d = np.empty(15, dtype=object)\n",
    "\n",
    "d[0],d[1],d[2],d[3],d[4],d[5],d[6],d[7],d[8],d[9],d[10],d[11],d[12],d[13] = np.hsplit(train_values, 14)\n",
    "d[0],d[14] = np.hsplit(train_labels, 2)\n",
    "\n",
    "atributes = {}\n",
    "\n",
    "for n,obj in enumerate(d):\n",
    "    atributes[n] = obj[0][0]\n",
    "    d[n] = np.squeeze(d[n])[1:]\n",
    "\n",
    "#NOTE: the columns lable in pd.df is numeric. For a given column N, its property corresponds to atributes[N+1]\n",
    "data = pd.DataFrame(data=d[1],index=d[0])\n",
    "for n in range(15):\n",
    "    if n < 2:\n",
    "        continue\n",
    "    data[n-1] = d[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 14 features are describedbelow:\n",
    "\n",
    "- slope_of_peak_exercise_st_segment (type: int): the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "- thal (type: categorical): results of thallium stress test measuring blood flow to the heart, with possible values normal, fixed_defect, reversible_defect\n",
    "- resting_blood_pressure (type: int): resting blood pressure\n",
    "- chest_pain_type (type: int): chest pain type (4 values)\n",
    "- num_major_vessels (type: int): number of major vessels (0-3) colored by flourosopy\n",
    "- fasting_blood_sugar_gt_120_mg_per_dl (type: binary): fasting blood sugar > 120 mg/dl\n",
    "- resting_ekg_results (type: int): resting electrocardiographic results (values 0,1,2)\n",
    "- serum_cholesterol_mg_per_dl (type: int): serum cholestoral in mg/dl\n",
    "- oldpeak_eq_st_depression (type: float): oldpeak = ST depression induced by exercise relative to rest, a measure of abnormality in electrocardiograms\n",
    "- sex (type: binary): 0: female, 1: male\n",
    "- age (type: int): age in years\n",
    "- max_heart_rate_achieved (type: int): maximum heart rate achieved (beats per minute)\n",
    "- exercise_induced_angina (type: binary): exercise-induced chest pain (0: False, 1: True)\n",
    "- heart_disease_present (type: binary): 0: heart disease not present, 1: heart disease present \n",
    "\n",
    "NOTE: The index in data corresponds to patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atributes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     80\n",
       "Name: 13, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts for heart_disease_present in training data\n",
    "data[13].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      float64\n",
      "1     category\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "6      float64\n",
      "7      float64\n",
      "8      float64\n",
      "9      float64\n",
      "10     float64\n",
      "11     float64\n",
      "12     float64\n",
      "13       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3600</td>\n",
       "      <td>130.12</td>\n",
       "      <td>2.8100</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>245.46</td>\n",
       "      <td>0.62700</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>53.66</td>\n",
       "      <td>156.87</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.7875</td>\n",
       "      <td>132.80</td>\n",
       "      <td>3.5875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>253.90</td>\n",
       "      <td>1.48875</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>56.25</td>\n",
       "      <td>140.25</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       2       3     4       5       6       7        8       9   \\\n",
       "13                                                                          \n",
       "0   1.3600  130.12  2.8100  0.33  0.1600  0.9200  245.46  0.62700  0.5500   \n",
       "1   1.7875  132.80  3.5875  1.15  0.1625  1.2125  253.90  1.48875  0.8625   \n",
       "\n",
       "       10      11    12  \n",
       "13                       \n",
       "0   53.66  156.87  0.13  \n",
       "1   56.25  140.25  0.55  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (data.astype({0: 'float64', 1: 'category', 2: 'float64', 3: 'float64', 4: 'float64', 5: 'float64', 6: 'float64', 7: 'float64',\n",
    "                    8: 'float64', 9: 'float64', 10: 'float64', 11: 'float64', 12: 'float64', 13: 'int64'}))\n",
    "print(data.dtypes)\n",
    "\n",
    "# Average for each attribute whether or not heart_disease_present\n",
    "data.groupby(13).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed_defect</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>141.375000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>227.250000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.875000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>1.377551</td>\n",
       "      <td>129.775510</td>\n",
       "      <td>2.897959</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>250.255102</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>54.387755</td>\n",
       "      <td>154.938776</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reversible_defect</th>\n",
       "      <td>1.729730</td>\n",
       "      <td>132.256757</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.202703</td>\n",
       "      <td>1.429730</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>55.040541</td>\n",
       "      <td>143.716216</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0           2         3         4         5   \\\n",
       "1                                                                       \n",
       "fixed_defect       2.000000  141.375000  3.125000  0.625000  0.375000   \n",
       "normal             1.377551  129.775510  2.897959  0.530612  0.153061   \n",
       "reversible_defect  1.729730  132.256757  3.500000  0.918919  0.148649   \n",
       "\n",
       "                         6           7         8         9          10  \\\n",
       "1                                                                        \n",
       "fixed_defect       1.250000  227.250000  1.300000  1.000000  57.875000   \n",
       "normal             1.071429  250.255102  0.669388  0.510204  54.387755   \n",
       "reversible_defect  1.000000  250.202703  1.429730  0.891892  55.040541   \n",
       "\n",
       "                           11        12        13  \n",
       "1                                                  \n",
       "fixed_defect       136.000000  0.250000  0.500000  \n",
       "normal             154.938776  0.153061  0.204082  \n",
       "reversible_defect  143.716216  0.540541  0.756757  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Averages as separated by thalium stress test\n",
    "data.groupby(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1      2    3    4    5    6      7    8    9     10     11   12  \\\n",
      "0z64un  1.0   1  128.0  2.0  0.0  0.0  2.0  308.0  0.0  1.0  45.0  170.0  0.0   \n",
      "ryoo3j  2.0   1  110.0  3.0  0.0  0.0  0.0  214.0  1.6  0.0  54.0  158.0  0.0   \n",
      "yt1s1x  1.0   1  125.0  4.0  3.0  0.0  2.0  304.0  0.0  1.0  77.0  162.0  1.0   \n",
      "l2xjde  1.0   2  152.0  4.0  0.0  0.0  0.0  223.0  0.0  1.0  40.0  181.0  0.0   \n",
      "oyt4ek  3.0   2  178.0  1.0  0.0  0.0  2.0  270.0  4.2  1.0  59.0  145.0  0.0   \n",
      "\n",
      "        13  \n",
      "0z64un   0  \n",
      "ryoo3j   0  \n",
      "yt1s1x   1  \n",
      "l2xjde   1  \n",
      "oyt4ek   0  \n"
     ]
    }
   ],
   "source": [
    "category_col = data.select_dtypes(['category']).columns \n",
    "data[category_col] = data[category_col].apply(lambda x: x.cat.codes)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3600</td>\n",
       "      <td>1.14</td>\n",
       "      <td>130.12</td>\n",
       "      <td>2.8100</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>245.46</td>\n",
       "      <td>0.62700</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>53.66</td>\n",
       "      <td>156.87</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.7875</td>\n",
       "      <td>1.65</td>\n",
       "      <td>132.80</td>\n",
       "      <td>3.5875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>253.90</td>\n",
       "      <td>1.48875</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>56.25</td>\n",
       "      <td>140.25</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1       2       3     4       5       6       7        8   \\\n",
       "13                                                                        \n",
       "0   1.3600  1.14  130.12  2.8100  0.33  0.1600  0.9200  245.46  0.62700   \n",
       "1   1.7875  1.65  132.80  3.5875  1.15  0.1625  1.2125  253.90  1.48875   \n",
       "\n",
       "        9      10      11    12  \n",
       "13                               \n",
       "0   0.5500  53.66  156.87  0.13  \n",
       "1   0.8625  56.25  140.25  0.55  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thal = {0:'fixed_defect', 1:'normal', 2:'reversible_defect'}\n",
    "data.groupby(13).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1      2    3    4    5    6      7    8    9     10     11   12\n",
      "0z64un  1.0   1  128.0  2.0  0.0  0.0  2.0  308.0  0.0  1.0  45.0  170.0  0.0\n",
      "ryoo3j  2.0   1  110.0  3.0  0.0  0.0  0.0  214.0  1.6  0.0  54.0  158.0  0.0\n",
      "yt1s1x  1.0   1  125.0  4.0  3.0  0.0  2.0  304.0  0.0  1.0  77.0  162.0  1.0\n",
      "l2xjde  1.0   2  152.0  4.0  0.0  0.0  0.0  223.0  0.0  1.0  40.0  181.0  0.0\n",
      "oyt4ek  3.0   2  178.0  1.0  0.0  0.0  2.0  270.0  4.2  1.0  59.0  145.0  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:, data.columns != 13]\n",
    "y = np.array(data.loc[:, data.columns == 13]).reshape(180,)\n",
    "print(X.head())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  152\n",
      "Number of no heart disease in oversampled data 76\n",
      "Number of heart disease 76\n",
      "Proportion of no heart disease data in oversampled data is  0.5\n",
      "Proportion of heart disease data in oversampled data is  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "columns = X_train.columns\n",
    "sm_data_X, sm_data_y = sm.fit_sample(X_train, y_train)\n",
    "sm_data_X = pd.DataFrame(data = sm_data_X, columns = columns )\n",
    "sm_data_y= pd.DataFrame(sm_data_y) #IDK what you are trying to do here with the oversampling, i think you are trying to counter the uneven dist?\n",
    "\n",
    "scl = StandardScaler()\n",
    "scale = scl.fit(X_train)\n",
    "\n",
    "\n",
    "print(\"length of oversampled data is \",len(sm_data_X))\n",
    "print(\"Number of no heart disease in oversampled data\",len(sm_data_y[sm_data_y[0]==0]))\n",
    "print(\"Number of heart disease\",len(sm_data_y[sm_data_y[0]==1]))\n",
    "print(\"Proportion of no heart disease data in oversampled data is \",len(sm_data_y[sm_data_y[0]==0])/len(sm_data_X))\n",
    "print(\"Proportion of heart disease data in oversampled data is \",len(sm_data_y[sm_data_y[0]==1])/len(sm_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
      "log loss: 0.35368170125484716\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT data Normalization\n",
    "logreg = LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000, C=1)\n",
    "\n",
    "# fit the model with taining data\n",
    "logreg.fit(X_train,y_train) #there was a major dataleak here! make sure you dont test using the same data u used to train\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_prob = logreg.predict_proba(X_test)\n",
    "print(f'Accuracy of logistic regression classifier on test set: {logreg.score(X_test, y_test)}')\n",
    "lloss = log_loss(y_test, y_pred_prob)\n",
    "print(f'log loss: {lloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.3536771729189414\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8055555555555556\n",
    "    log loss: 0.36027304512739483\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='sag', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.3585651405396726\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='lbfgs', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.42470468568912534\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='newton-cg', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.42600636188623087\n",
    "###### LogisticRegression(multi_class = 'ovr', solver='liblinear', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8611111111111112\n",
    "    log loss: 0.3770715033919158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
      "log loss: 0.34888688795451994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.8611111111111112\n",
      "log loss: 0.39863444533078496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:19: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:20: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "#WITH data Normalization\n",
    "logreg = LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000, C=0.2)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(scl.transform(X_train),y_train)\n",
    "y_pred=logreg.predict(scl.transform((X_test)))\n",
    "y_pred_prob = logreg.predict_proba(scl.transform(X_test))\n",
    "print(f'Accuracy of logistic regression classifier on test set: {logreg.score(scl.transform(X_test), y_test)}')\n",
    "lloss = log_loss(y_test, y_pred_prob)\n",
    "print(f'log loss: {lloss}')\n",
    "\n",
    "\n",
    "\n",
    "#WITH data Normalization\n",
    "logregCV = LogisticRegressionCV(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000, Cs =100)\n",
    "\n",
    "# fit the model with data\n",
    "logregCV.fit(scl.transform(X_train),y_train)\n",
    "y_predCV=logregCV.predict(scl.transform((X_test)))\n",
    "y_pred_probCV = logregCV.predict_proba(scl.transform(X_test))\n",
    "print(f'Accuracy of logistic regression classifier on test set: {logregCV.score(scl.transform(X_test), y_test)}')\n",
    "llossCV = log_loss(y_test, y_pred_probCV)\n",
    "print(f'log loss: {llossCV}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  5]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86        24\n",
      "           1       0.69      0.92      0.79        12\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        36\n",
      "   macro avg       0.82      0.85      0.82        36\n",
      "weighted avg       0.86      0.83      0.84        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n",
    "# The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "# The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "# The F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n",
    "# The support is the number of occurrences of each class in y_test.\n",
    "\n",
    "confMatrix = confusion_matrix(y_test, y_pred)\n",
    "print(confMatrix)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  6]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84        24\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        36\n",
      "   macro avg       0.80      0.83      0.80        36\n",
      "weighted avg       0.85      0.81      0.81        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM without normalization\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)  \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  6]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84        24\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        36\n",
      "   macro avg       0.80      0.83      0.80        36\n",
      "weighted avg       0.85      0.81      0.81        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM with normalization\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(scl.transform(X_train), y_train)  \n",
    "y_pred = svclassifier.predict(scl.transform(X_test))  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10]\n",
      "Polynomial Degree:  2\n",
      "[[18  6]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84        24\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        36\n",
      "   macro avg       0.80      0.83      0.80        36\n",
      "weighted avg       0.85      0.81      0.81        36\n",
      "\n",
      "Polynomial Degree:  3\n",
      "[[17  7]\n",
      " [ 2 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79        24\n",
      "           1       0.59      0.83      0.69        12\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        36\n",
      "   macro avg       0.74      0.77      0.74        36\n",
      "weighted avg       0.79      0.75      0.76        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "degrees =np.arange(2,11)\n",
    "print(degrees)\n",
    "\n",
    "for deg in degrees:\n",
    "    svclassifier = SVC(kernel='poly', degree = deg, gamma = 'scale')  \n",
    "    svclassifier.fit(X_train, y_train) \n",
    "    y_pred = svclassifier.predict(X_test)  \n",
    "    print(\"Polynomial Degree: \", deg)\n",
    "    print(confusion_matrix(y_test,y_pred))  \n",
    "    print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='poly', degree=3, gamma = 'auto', probability = True)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "y_pred_prob = svclassifier.predict_proba(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "svclassifier = SVC(kernel='poly', degree=3, gamma = 'scale', probability = True)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "y_pred_prob = svclassifier.predict_proba(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='poly', degree=3, gamma = 'auto')  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "rfe = RFECV(svclassifier)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "print(rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfe.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfe.grid_scores_) + 1), rfe.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(rfe.support_):\n",
    "    if i:\n",
    "        print(atributes[n+1])\n",
    "        \n",
    "logregmask = [0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
    "\n",
    "print(f\"\\nWith LogReg Classififier:\")\n",
    "mainfeatures = []\n",
    "for n, i in enumerate(logregmask):\n",
    "    if not i:\n",
    "        mainfeatures.append(n)\n",
    "        continue;\n",
    "    if not rfe.support_[n]:\n",
    "        mainfeatures.append(n)\n",
    "            \n",
    "print(mainfeatures)\n",
    "prim = [1,3,4,8,9,12,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = copy.deepcopy(data)\n",
    "data6.drop(axis=1, labels=mainfeatures , inplace=True)\n",
    "othfeat = [0,5,6]\n",
    "data6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan = [copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data)]\n",
    "templist = [0,5,6,[0,5],[0,6],[5,6],[0,5,6]]\n",
    "fet = np.arange(1,13)\n",
    "\n",
    "for n,itm in enumerate(templist):\n",
    "    if (n == 0):\n",
    "        mask = np.in1d(fet, [0]+prim, invert=True)\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 1:\n",
    "        mask = np.in1d(fet, [5]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 2:\n",
    "        mask = np.in1d(fet, [6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 3:\n",
    "        mask = np.in1d(fet, [0,5]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 4:\n",
    "        mask = np.in1d(fet, [0,6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 5:\n",
    "        mask = np.in1d(fet, [5,6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 6:\n",
    "        mask = np.in1d(fet, [0,5,6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "        \n",
    "        \n",
    "    #s = set(mainfeatures)\n",
    "    #for i in [itm]:\n",
    "    #    s.remove(i)\n",
    "    #print(s)\n",
    "    #mask = np.in1d(fet, s, invert=True)\n",
    "    #print(fet[mask])\n",
    "    #datan[n] = copy.deepcopy(data)\n",
    "    #datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class = 'multinomial', solver='sag', penalty='l2', max_iter=10000)\n",
    "datak = datan[0]\n",
    "X = datak.loc[:, datak.columns != 13]\n",
    "y = np.array(datak.loc[:, datak.columns == 13]).reshape(180,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "logreg.fit(X_train,y_train) #there was a major dataleak here! make sure you dont test using the same data u used to train\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_prob = logreg.predict_proba(X_test)\n",
    "print(f'Accuracy of logistic regression classifier on test set: {logreg.score(X_test, y_test)}')\n",
    "lloss = log_loss(y_test, y_pred_prob)\n",
    "print(f'log loss: {lloss}')\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=80) #5 Fold CV\n",
    "logreg1 = LogisticRegression(multi_class = 'multinomial', solver='newton-cg', penalty='l2', max_iter=10000, C=0.02)\n",
    "y_pred = np.zeros(180)\n",
    "y_pred_prob = np.zeros((180,2))\n",
    "\n",
    "for train, test in skf.split(X,y):\n",
    "    logreg1.fit(X.iloc[train],y[train])\n",
    "    y_pred[test] = logreg1.predict(X.iloc[test])\n",
    "    y_pred_prob[test] = logreg1.predict_proba(X.iloc[test])\n",
    "    \n",
    "lloss = log_loss(y, y_pred_prob)\n",
    "print(f'log loss: {lloss}')\n",
    "hplotls = sns.heatmap(confusion_matrix(y,y_pred),annot=True, cmap = 'coolwarm')\n",
    "fig1 = hplotls.get_figure()\n",
    "fig1.savefig('hplotlreg.pdf',dpi=5000)\n",
    "print(classification_report(y,y_pred)) \n",
    "\n",
    "logit_roc_auc = roc_auc_score(y, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_prob[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roclreg.pdf',dpi=5000)\n",
    "print(logreg1.coef_)\n",
    "datan[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datak = datan[4]\n",
    "X = datak.loc[:, datak.columns != 13]\n",
    "y = np.array(datak.loc[:, datak.columns == 13]).reshape(180,)\n",
    "svc1 = SVC(kernel='poly', degree=3, gamma = 'auto', C=0.05,)  \n",
    "y_predsvm = np.zeros(180)\n",
    "\n",
    "for train, test in skf.split(X,y):\n",
    "    svc1.fit(X.iloc[train],y[train])\n",
    "    y_predsvm[test] = svc1.predict(X.iloc[test])\n",
    "    #y_pred_prob[test] = svc1.predict_proba(X.iloc[test])\n",
    "    \n",
    "#lloss = log_loss(y, y_pred_prob)\n",
    "#print(f'log loss: {lloss}')\n",
    "#cmap = sns.palplot(sns.color_palette(\"coolwarm\", 2))\n",
    "\n",
    "hplotsvm = sns.heatmap(confusion_matrix(y,y_predsvm),annot=True, cmap = 'coolwarm')\n",
    "fig2 = hplotls.get_figure()\n",
    "fig2.savefig('hplotsvm.png',dpi=5000)\n",
    "print(classification_report(y,y_predsvm)) \n",
    "\n",
    "logit_roc_auc = roc_auc_score(y, y_predsvm)\n",
    "fpr, tpr, thresholds = roc_curve(y, y_predsvm)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('rocsvm.png',dpi=5000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird = np.concatenate((y_predsvm.reshape(180,1), y_pred.reshape(180,1), y),axis=1 )\n",
    "y_predw = np.zeros(180)\n",
    "y_pred_probw = np.zeros((180,2))\n",
    "logreg2 = LogisticRegression(multi_class = 'multinomial', solver='newton-cg', penalty='l2', max_iter=10000)\n",
    "\n",
    "for train, test in skf.split(weird,y):\n",
    "    logreg2.fit(weird[train],y[train])\n",
    "    y_predw[test] = logreg2.predict(weird[test])\n",
    "    y_pred_probw[test] = logreg2.predict_proba(weird[test])\n",
    "    \n",
    "lloss = log_loss(y, y_pred_probw)\n",
    "print(f'log loss: {lloss}')\n",
    "sns.heatmap(confusion_matrix(y,y_predw),annot=True, cmap = 'coolwarm')\n",
    "print(classification_report(y,y_predw)) \n",
    "\n",
    "logit_roc_auc = roc_auc_score(y, y_predw)\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_probw[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird = np.concatenate((y_predsvm.reshape(180,1), y_pred.reshape(180,1), y.reshape(180,1)),axis=1 )\n",
    "#print(weird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newres = np.zeros(180)\n",
    "\n",
    "for n,i in enumerate(y_pred):\n",
    "    if i == y_predsvm[n]:\n",
    "        newres[n] = i\n",
    "        continue    \n",
    "    else:\n",
    "        newres[n] = y_predsvm[n]\n",
    "        #print(weird[n])\n",
    "        #print(data6.iloc[n])\n",
    "        \n",
    "sns.heatmap(confusion_matrix(y,newres),annot=True, cmap = 'coolwarm')\n",
    "print(classification_report(y,newres)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
