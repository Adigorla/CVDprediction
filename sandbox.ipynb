{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, LeaveOneOut\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.metrics import r2_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import log_loss, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "# from sklearn.exceptions import DataConversionWarning\n",
    "# warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "train_values = np.loadtxt(\"train_values.csv\", delimiter=\",\", dtype=object)\n",
    "train_labels = np.loadtxt(\"train_labels.csv\", delimiter=\",\", dtype=object)\n",
    "\n",
    "d = np.empty(15, dtype=object)\n",
    "\n",
    "d[0],d[1],d[2],d[3],d[4],d[5],d[6],d[7],d[8],d[9],d[10],d[11],d[12],d[13] = np.hsplit(train_values, 14)\n",
    "d[0],d[14] = np.hsplit(train_labels, 2)\n",
    "\n",
    "atributes = {}\n",
    "\n",
    "for n,obj in enumerate(d):\n",
    "    atributes[n] = obj[0][0]\n",
    "    d[n] = np.squeeze(d[n])[1:]\n",
    "\n",
    "#NOTE: the columns lable in pd.df is numeric. For a given column N, its property corresponds to atributes[N+1]\n",
    "data = pd.DataFrame(data=d[1],index=d[0])\n",
    "for n in range(15):\n",
    "    if n < 2:\n",
    "        continue\n",
    "    data[n-1] = d[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 14 features are describedbelow:\n",
    "\n",
    "- slope_of_peak_exercise_st_segment (type: int): the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "- thal (type: categorical): results of thallium stress test measuring blood flow to the heart, with possible values normal, fixed_defect, reversible_defect\n",
    "- resting_blood_pressure (type: int): resting blood pressure\n",
    "- chest_pain_type (type: int): chest pain type (4 values)\n",
    "- num_major_vessels (type: int): number of major vessels (0-3) colored by flourosopy\n",
    "- fasting_blood_sugar_gt_120_mg_per_dl (type: binary): fasting blood sugar > 120 mg/dl\n",
    "- resting_ekg_results (type: int): resting electrocardiographic results (values 0,1,2)\n",
    "- serum_cholesterol_mg_per_dl (type: int): serum cholestoral in mg/dl\n",
    "- oldpeak_eq_st_depression (type: float): oldpeak = ST depression induced by exercise relative to rest, a measure of abnormality in electrocardiograms\n",
    "- sex (type: binary): 0: female, 1: male\n",
    "- age (type: int): age in years\n",
    "- max_heart_rate_achieved (type: int): maximum heart rate achieved (beats per minute)\n",
    "- exercise_induced_angina (type: binary): exercise-induced chest pain (0: False, 1: True)\n",
    "- heart_disease_present (type: binary): 0: heart disease not present, 1: heart disease present \n",
    "\n",
    "NOTE: The index in data corresponds to patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'patient_id', 1: 'slope_of_peak_exercise_st_segment', 2: 'thal', 3: 'resting_blood_pressure', 4: 'chest_pain_type', 5: 'num_major_vessels', 6: 'fasting_blood_sugar_gt_120_mg_per_dl', 7: 'resting_ekg_results', 8: 'serum_cholesterol_mg_per_dl', 9: 'oldpeak_eq_st_depression', 10: 'sex', 11: 'age', 12: 'max_heart_rate_achieved', 13: 'exercise_induced_angina', 14: 'heart_disease_present'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                  1    2  3  4  5  6    7    8  9   10   11 12 13\n",
       "0z64un  1             normal  128  2  0  0  2  308  0.0  1  45  170  0  0\n",
       "ryoo3j  2             normal  110  3  0  0  0  214  1.6  0  54  158  0  0\n",
       "yt1s1x  1             normal  125  4  3  0  2  304  0.0  1  77  162  1  1\n",
       "l2xjde  1  reversible_defect  152  4  0  0  0  223  0.0  1  40  181  0  1\n",
       "oyt4ek  3  reversible_defect  178  1  0  0  2  270  4.2  1  59  145  0  0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(atributes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     80\n",
       "Name: 13, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts for heart_disease_present in training data\n",
    "data[13].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      float64\n",
      "1     category\n",
      "2      float64\n",
      "3      float64\n",
      "4      float64\n",
      "5      float64\n",
      "6      float64\n",
      "7      float64\n",
      "8      float64\n",
      "9      float64\n",
      "10     float64\n",
      "11     float64\n",
      "12     float64\n",
      "13       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3600</td>\n",
       "      <td>130.12</td>\n",
       "      <td>2.8100</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>245.46</td>\n",
       "      <td>0.62700</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>53.66</td>\n",
       "      <td>156.87</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.7875</td>\n",
       "      <td>132.80</td>\n",
       "      <td>3.5875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>253.90</td>\n",
       "      <td>1.48875</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>56.25</td>\n",
       "      <td>140.25</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       2       3     4       5       6       7        8       9   \\\n",
       "13                                                                          \n",
       "0   1.3600  130.12  2.8100  0.33  0.1600  0.9200  245.46  0.62700  0.5500   \n",
       "1   1.7875  132.80  3.5875  1.15  0.1625  1.2125  253.90  1.48875  0.8625   \n",
       "\n",
       "       10      11    12  \n",
       "13                       \n",
       "0   53.66  156.87  0.13  \n",
       "1   56.25  140.25  0.55  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (data.astype({0: 'float64', 1: 'category', 2: 'float64', 3: 'float64', 4: 'float64', 5: 'float64', 6: 'float64', 7: 'float64',\n",
    "                    8: 'float64', 9: 'float64', 10: 'float64', 11: 'float64', 12: 'float64', 13: 'int64'}))\n",
    "print(data.dtypes)\n",
    "\n",
    "# Average for each attribute whether or not heart_disease_present\n",
    "data.groupby(13).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed_defect</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>141.375000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>227.250000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.875000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>1.377551</td>\n",
       "      <td>129.775510</td>\n",
       "      <td>2.897959</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>250.255102</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>54.387755</td>\n",
       "      <td>154.938776</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reversible_defect</th>\n",
       "      <td>1.729730</td>\n",
       "      <td>132.256757</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.202703</td>\n",
       "      <td>1.429730</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>55.040541</td>\n",
       "      <td>143.716216</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0           2         3         4         5   \\\n",
       "1                                                                       \n",
       "fixed_defect       2.000000  141.375000  3.125000  0.625000  0.375000   \n",
       "normal             1.377551  129.775510  2.897959  0.530612  0.153061   \n",
       "reversible_defect  1.729730  132.256757  3.500000  0.918919  0.148649   \n",
       "\n",
       "                         6           7         8         9          10  \\\n",
       "1                                                                        \n",
       "fixed_defect       1.250000  227.250000  1.300000  1.000000  57.875000   \n",
       "normal             1.071429  250.255102  0.669388  0.510204  54.387755   \n",
       "reversible_defect  1.000000  250.202703  1.429730  0.891892  55.040541   \n",
       "\n",
       "                           11        12        13  \n",
       "1                                                  \n",
       "fixed_defect       136.000000  0.250000  0.500000  \n",
       "normal             154.938776  0.153061  0.204082  \n",
       "reversible_defect  143.716216  0.540541  0.756757  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Averages as separated by thalium stress test\n",
    "data.groupby(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1      2    3    4    5    6      7    8    9     10     11   12  \\\n",
      "0z64un  1.0   1  128.0  2.0  0.0  0.0  2.0  308.0  0.0  1.0  45.0  170.0  0.0   \n",
      "ryoo3j  2.0   1  110.0  3.0  0.0  0.0  0.0  214.0  1.6  0.0  54.0  158.0  0.0   \n",
      "yt1s1x  1.0   1  125.0  4.0  3.0  0.0  2.0  304.0  0.0  1.0  77.0  162.0  1.0   \n",
      "l2xjde  1.0   2  152.0  4.0  0.0  0.0  0.0  223.0  0.0  1.0  40.0  181.0  0.0   \n",
      "oyt4ek  3.0   2  178.0  1.0  0.0  0.0  2.0  270.0  4.2  1.0  59.0  145.0  0.0   \n",
      "\n",
      "        13  \n",
      "0z64un   0  \n",
      "ryoo3j   0  \n",
      "yt1s1x   1  \n",
      "l2xjde   1  \n",
      "oyt4ek   0  \n"
     ]
    }
   ],
   "source": [
    "category_col = data.select_dtypes(['category']).columns \n",
    "data[category_col] = data[category_col].apply(lambda x: x.cat.codes)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3600</td>\n",
       "      <td>1.14</td>\n",
       "      <td>130.12</td>\n",
       "      <td>2.8100</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>245.46</td>\n",
       "      <td>0.62700</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>53.66</td>\n",
       "      <td>156.87</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.7875</td>\n",
       "      <td>1.65</td>\n",
       "      <td>132.80</td>\n",
       "      <td>3.5875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>1.2125</td>\n",
       "      <td>253.90</td>\n",
       "      <td>1.48875</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>56.25</td>\n",
       "      <td>140.25</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1       2       3     4       5       6       7        8   \\\n",
       "13                                                                        \n",
       "0   1.3600  1.14  130.12  2.8100  0.33  0.1600  0.9200  245.46  0.62700   \n",
       "1   1.7875  1.65  132.80  3.5875  1.15  0.1625  1.2125  253.90  1.48875   \n",
       "\n",
       "        9      10      11    12  \n",
       "13                               \n",
       "0   0.5500  53.66  156.87  0.13  \n",
       "1   0.8625  56.25  140.25  0.55  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thal = {0:'fixed_defect', 1:'normal', 2:'reversible_defect'}\n",
    "data.groupby(13).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1      2    3    4    5    6      7    8    9     10     11   12\n",
      "0z64un  1.0   1  128.0  2.0  0.0  0.0  2.0  308.0  0.0  1.0  45.0  170.0  0.0\n",
      "ryoo3j  2.0   1  110.0  3.0  0.0  0.0  0.0  214.0  1.6  0.0  54.0  158.0  0.0\n",
      "yt1s1x  1.0   1  125.0  4.0  3.0  0.0  2.0  304.0  0.0  1.0  77.0  162.0  1.0\n",
      "l2xjde  1.0   2  152.0  4.0  0.0  0.0  0.0  223.0  0.0  1.0  40.0  181.0  0.0\n",
      "oyt4ek  3.0   2  178.0  1.0  0.0  0.0  2.0  270.0  4.2  1.0  59.0  145.0  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180, 13)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:, data.columns != 13]\n",
    "y = np.array(data.loc[:, data.columns == 13]).reshape(180,)\n",
    "print(X.head())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  152\n",
      "Number of no heart disease in oversampled data 76\n",
      "Number of heart disease 76\n",
      "Proportion of no heart disease data in oversampled data is  0.5\n",
      "Proportion of heart disease data in oversampled data is  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "columns = X_train.columns\n",
    "sm_data_X, sm_data_y = sm.fit_sample(X_train, y_train)\n",
    "sm_data_X = pd.DataFrame(data = sm_data_X, columns = columns )\n",
    "sm_data_y= pd.DataFrame(sm_data_y) #IDK what you are trying to do here with the oversampling, i think you are trying to counter the uneven dist?\n",
    "\n",
    "scl = StandardScaler()\n",
    "scale = scl.fit(X_train)\n",
    "\n",
    "\n",
    "print(\"length of oversampled data is \",len(sm_data_X))\n",
    "print(\"Number of no heart disease in oversampled data\",len(sm_data_y[sm_data_y[0]==0]))\n",
    "print(\"Number of heart disease\",len(sm_data_y[sm_data_y[0]==1]))\n",
    "print(\"Proportion of no heart disease data in oversampled data is \",len(sm_data_y[sm_data_y[0]==0])/len(sm_data_X))\n",
    "print(\"Proportion of heart disease data in oversampled data is \",len(sm_data_y[sm_data_y[0]==1])/len(sm_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
      "log loss: 0.3536654718058519\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT data Normalization\n",
    "logreg = LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000, C=1)\n",
    "\n",
    "# fit the model with taining data\n",
    "logreg.fit(X_train,y_train) #there was a major dataleak here! make sure you dont test using the same data u used to train\n",
    "y_pred=logreg.predict(X_test)\n",
    "y_pred_prob = logreg.predict_proba(X_test)\n",
    "print(f'Accuracy of logistic regression classifier on test set: {logreg.score(X_test, y_test)}')\n",
    "lloss = log_loss(y_test, y_pred_prob)\n",
    "print(f'log loss: {lloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.3536771729189414\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8055555555555556\n",
    "    log loss: 0.36027304512739483\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='sag', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.3585651405396726\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='lbfgs', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.42470468568912534\n",
    "###### LogisticRegression(multi_class = 'multinomial', solver='newton-cg', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
    "    log loss: 0.42600636188623087\n",
    "###### LogisticRegression(multi_class = 'ovr', solver='liblinear', penalty='l2', max_iter=10000)\n",
    "    Accuracy of logistic regression classifier on test set: 0.8611111111111112\n",
    "    log loss: 0.3770715033919158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.8333333333333334\n",
      "log loss: 0.3488819272206161\n",
      "Accuracy of logistic regression classifier on test set: 0.8611111111111112\n",
      "log loss: 0.3986348238061503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:19: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:20: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "#WITH data Normalization\n",
    "logreg = LogisticRegression(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000, C=0.2)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(scl.transform(X_train),y_train)\n",
    "y_pred=logreg.predict(scl.transform((X_test)))\n",
    "y_pred_prob = logreg.predict_proba(scl.transform(X_test))\n",
    "print(f'Accuracy of logistic regression classifier on test set: {logreg.score(scl.transform(X_test), y_test)}')\n",
    "lloss = log_loss(y_test, y_pred_prob)\n",
    "print(f'log loss: {lloss}')\n",
    "\n",
    "\n",
    "\n",
    "#WITH data Normalization\n",
    "logregCV = LogisticRegressionCV(multi_class = 'multinomial', solver='saga', penalty='l1', max_iter=10000, Cs =100)\n",
    "\n",
    "# fit the model with data\n",
    "logregCV.fit(scl.transform(X_train),y_train)\n",
    "y_predCV=logregCV.predict(scl.transform((X_test)))\n",
    "y_pred_probCV = logregCV.predict_proba(scl.transform(X_test))\n",
    "print(f'Accuracy of logistic regression classifier on test set: {logregCV.score(scl.transform(X_test), y_test)}')\n",
    "llossCV = log_loss(y_test, y_pred_probCV)\n",
    "print(f'log loss: {llossCV}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  5]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86        24\n",
      "           1       0.69      0.92      0.79        12\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        36\n",
      "   macro avg       0.82      0.85      0.82        36\n",
      "weighted avg       0.86      0.83      0.84        36\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n",
    "# The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "# The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "# The F-beta score weights the recall more than the precision by a factor of beta. beta = 1.0 means recall and precision are equally important.\n",
    "# The support is the number of occurrences of each class in y_test.\n",
    "\n",
    "confMatrix = confusion_matrix(y_test, y_pred)\n",
    "print(confMatrix)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  6]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84        24\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        36\n",
      "   macro avg       0.80      0.83      0.80        36\n",
      "weighted avg       0.85      0.81      0.81        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM without normalization\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, y_train)  \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  6]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84        24\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        36\n",
      "   macro avg       0.80      0.83      0.80        36\n",
      "weighted avg       0.85      0.81      0.81        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int8, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM with normalization\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(scl.transform(X_train), y_train)  \n",
    "y_pred = svclassifier.predict(scl.transform(X_test))  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10]\n",
      "Polynomial Degree:  2\n",
      "[[18  6]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84        24\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "   micro avg       0.81      0.81      0.81        36\n",
      "   macro avg       0.80      0.83      0.80        36\n",
      "weighted avg       0.85      0.81      0.81        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "degrees =np.arange(2,11)\n",
    "print(degrees)\n",
    "\n",
    "for deg in degrees:\n",
    "    svclassifier = SVC(kernel='poly', degree = deg, gamma = 'scale')  \n",
    "    svclassifier.fit(X_train, y_train) \n",
    "    y_pred = svclassifier.predict(X_test)  \n",
    "    print(\"Polynomial Degree: \", deg)\n",
    "    print(confusion_matrix(y_test,y_pred))  \n",
    "    print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='poly', degree=3, gamma = 'auto', probability = True)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "y_pred_prob = svclassifier.predict_proba(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) \n",
    "\n",
    "svclassifier = SVC(kernel='poly', degree=3, gamma = 'scale', probability = True)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "y_pred_prob = svclassifier.predict_proba(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='poly', degree=3, gamma = 'auto')  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilay\\Anaconda3\\envs\\BE188\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True  True  True False False  True  True False False\n",
      "  True]\n",
      "[1 1 3 1 1 1 2 6 1 1 4 5 1]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "rfe = RFECV(svclassifier)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "print(rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72272278 0.72272278 0.71592609 0.7299567  0.75079606 0.75817171\n",
      " 0.79956699 0.8206898  0.81331416 0.77134595 0.77134595 0.79232101\n",
      " 0.77872763]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfe.grid_scores_) + 1), rfe.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope_of_peak_exercise_st_segment\n",
      "thal\n",
      "chest_pain_type\n",
      "num_major_vessels\n",
      "fasting_blood_sugar_gt_120_mg_per_dl\n",
      "oldpeak_eq_st_depression\n",
      "sex\n",
      "exercise_induced_angina\n",
      "\n",
      "With LogReg Classififier:\n",
      "[0, 2, 5, 6, 7, 10, 11]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1      2    3    4    5    6      7    8    9     10     11   12  \\\n",
       "0z64un  1.0   1  128.0  2.0  0.0  0.0  2.0  308.0  0.0  1.0  45.0  170.0  0.0   \n",
       "ryoo3j  2.0   1  110.0  3.0  0.0  0.0  0.0  214.0  1.6  0.0  54.0  158.0  0.0   \n",
       "yt1s1x  1.0   1  125.0  4.0  3.0  0.0  2.0  304.0  0.0  1.0  77.0  162.0  1.0   \n",
       "l2xjde  1.0   2  152.0  4.0  0.0  0.0  0.0  223.0  0.0  1.0  40.0  181.0  0.0   \n",
       "oyt4ek  3.0   2  178.0  1.0  0.0  0.0  2.0  270.0  4.2  1.0  59.0  145.0  0.0   \n",
       "\n",
       "        13  \n",
       "0z64un   0  \n",
       "ryoo3j   0  \n",
       "yt1s1x   1  \n",
       "l2xjde   1  \n",
       "oyt4ek   0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n, i in enumerate(rfe.support_):\n",
    "    if i:\n",
    "        print(atributes[n+1])\n",
    "        \n",
    "logregmask = [0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
    "\n",
    "print(f\"\\nWith LogReg Classififier:\")\n",
    "mainfeatures = []\n",
    "for n, i in enumerate(logregmask):\n",
    "    if not i:\n",
    "        mainfeatures.append(n)\n",
    "        continue;\n",
    "    if not rfe.support_[n]:\n",
    "        mainfeatures.append(n)\n",
    "            \n",
    "print(mainfeatures)\n",
    "prim = [1,3,4,8,9,12,13]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1      2    3    4    5    6      7    8    9     10     11   12  \\\n",
       "0z64un  1.0   1  128.0  2.0  0.0  0.0  2.0  308.0  0.0  1.0  45.0  170.0  0.0   \n",
       "ryoo3j  2.0   1  110.0  3.0  0.0  0.0  0.0  214.0  1.6  0.0  54.0  158.0  0.0   \n",
       "yt1s1x  1.0   1  125.0  4.0  3.0  0.0  2.0  304.0  0.0  1.0  77.0  162.0  1.0   \n",
       "l2xjde  1.0   2  152.0  4.0  0.0  0.0  0.0  223.0  0.0  1.0  40.0  181.0  0.0   \n",
       "oyt4ek  3.0   2  178.0  1.0  0.0  0.0  2.0  270.0  4.2  1.0  59.0  145.0  0.0   \n",
       "\n",
       "        13  \n",
       "0z64un   0  \n",
       "ryoo3j   0  \n",
       "yt1s1x   1  \n",
       "l2xjde   1  \n",
       "oyt4ek   0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6 = copy.deepcopy(data)\n",
    "data6.drop(axis=1, labels=mainfeatures , inplace=True)\n",
    "othfeat = [0,5,6]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "datan = [copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data),copy.deepcopy(data)]\n",
    "templist = [0,5,6,[0,5],[0,6],[5,6],[0,5,6]]\n",
    "fet = np.arange(0,13)\n",
    "\n",
    "for n,itm in enumerate(templist):\n",
    "    if (n == 0):\n",
    "        mask = np.in1d(fet, [0]+prim, invert=True)\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 1:\n",
    "        mask = np.in1d(fet, [5]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 2:\n",
    "        mask = np.in1d(fet, [6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 3:\n",
    "        mask = np.in1d(fet, [0,5]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 4:\n",
    "        mask = np.in1d(fet, [0,6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 5:\n",
    "        mask = np.in1d(fet, [5,6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    elif n == 6:\n",
    "        mask = np.in1d(fet, [0,5,6]+prim, invert=True)\n",
    "\n",
    "        datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "        \n",
    "        \n",
    "    #s = set(mainfeatures)\n",
    "    #for i in [itm]:\n",
    "    #    s.remove(i)\n",
    "    #print(s)\n",
    "    #mask = np.in1d(fet, s, invert=True)\n",
    "    #print(fet[mask])\n",
    "    #datan[n] = copy.deepcopy(data)\n",
    "    #datan[n].drop(axis=1, labels=fet[mask] , inplace=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1      2    3    4    5    6      7    8    9     10     11   12  \\\n",
       "0z64un  1.0   1  128.0  2.0  0.0  0.0  2.0  308.0  0.0  1.0  45.0  170.0  0.0   \n",
       "ryoo3j  2.0   1  110.0  3.0  0.0  0.0  0.0  214.0  1.6  0.0  54.0  158.0  0.0   \n",
       "yt1s1x  1.0   1  125.0  4.0  3.0  0.0  2.0  304.0  0.0  1.0  77.0  162.0  1.0   \n",
       "l2xjde  1.0   2  152.0  4.0  0.0  0.0  0.0  223.0  0.0  1.0  40.0  181.0  0.0   \n",
       "oyt4ek  3.0   2  178.0  1.0  0.0  0.0  2.0  270.0  4.2  1.0  59.0  145.0  0.0   \n",
       "\n",
       "        13  \n",
       "0z64un   0  \n",
       "ryoo3j   0  \n",
       "yt1s1x   1  \n",
       "l2xjde   1  \n",
       "oyt4ek   0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "datan.insert(0, data6)\n",
    "datan = np.array(datan)\n",
    "print(datan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0   1    3    4    6    8    9    12  13\n",
      "0z64un  1.0   1  2.0  0.0  2.0  0.0  1.0  0.0   0\n",
      "ryoo3j  2.0   1  3.0  0.0  0.0  1.6  0.0  0.0   0\n",
      "yt1s1x  1.0   1  4.0  3.0  2.0  0.0  1.0  1.0   1\n",
      "l2xjde  1.0   2  4.0  0.0  0.0  0.0  1.0  0.0   1\n",
      "oyt4ek  3.0   2  1.0  0.0  2.0  4.2  1.0  0.0   0\n",
      "[[19  5]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86        24\n",
      "           1       0.69      0.92      0.79        12\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        36\n",
      "   macro avg       0.82      0.85      0.82        36\n",
      "weighted avg       0.86      0.83      0.84        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.8333333333333334\n",
      "[[19  5]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88        24\n",
      "           1       0.71      1.00      0.83        12\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        36\n",
      "   macro avg       0.85      0.90      0.86        36\n",
      "weighted avg       0.90      0.86      0.87        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.8611111111111112\n",
      "[[19  5]\n",
      " [ 3  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.83        24\n",
      "           1       0.64      0.75      0.69        12\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        36\n",
      "   macro avg       0.75      0.77      0.76        36\n",
      "weighted avg       0.79      0.78      0.78        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.7777777777777778\n",
      "[[20  4]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        24\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        36\n",
      "   macro avg       0.88      0.92      0.88        36\n",
      "weighted avg       0.92      0.89      0.89        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.8888888888888888\n",
      "[[19  5]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86        24\n",
      "           1       0.69      0.92      0.79        12\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        36\n",
      "   macro avg       0.82      0.85      0.82        36\n",
      "weighted avg       0.86      0.83      0.84        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.8333333333333334\n",
      "[[20  4]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        24\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        36\n",
      "   macro avg       0.88      0.92      0.88        36\n",
      "weighted avg       0.92      0.89      0.89        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.8888888888888888\n",
      "[[20  4]\n",
      " [ 1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89        24\n",
      "           1       0.73      0.92      0.81        12\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        36\n",
      "   macro avg       0.84      0.88      0.85        36\n",
      "weighted avg       0.88      0.86      0.86        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.8611111111111112\n",
      "[[20  4]\n",
      " [ 0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        24\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        36\n",
      "   macro avg       0.88      0.92      0.88        36\n",
      "weighted avg       0.92      0.89      0.89        36\n",
      "\n",
      "Accuracy of support vector classifier on test set: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "#X, y, X_train, X_test, y_train, y_test = ( for i in range(6))\n",
    "print(datan[5].head())\n",
    "for i, d in enumerate(datan):\n",
    "    X = d.loc[:, d.columns != 13]\n",
    "    y = np.array(d.loc[:, d.columns == 13]).reshape(180,)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    svclassifier = SVC(kernel='poly', degree=3, gamma = 'auto')  \n",
    "    svclassifier.fit(X_train, y_train) \n",
    "    y_pred = svclassifier.predict(X_test)\n",
    "    print(confusion_matrix(y_test,y_pred))  \n",
    "    print(classification_report(y_test,y_pred)) \n",
    "    print(f'Accuracy of support vector classifier on test set: {svclassifier.score(X_test, y_test)}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
